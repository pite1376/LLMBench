---
description: 
globs: 
alwaysApply: false
---
# AI服务开发规范

## AI服务架构概述
本项目的AI服务采用统一抽象层设计，核心文件：
- **服务主入口**: [src/services/ai-service.ts](mdc:src/services/ai-service.ts) - 统一的AI服务接口
- **模型配置**: [src/lib/models.ts](mdc:src/lib/models.ts) - 所有AI模型的配置和定义
- **Claude服务**: [src/services/claudeService.ts](mdc:src/services/claudeService.ts) - Claude AI专用服务
- **AI类型定义**: [src/types/index.ts](mdc:src/types/index.ts) - AI相关的TypeScript类型

## AI模型集成标准

### 1. 模型配置规范
所有AI模型必须在 [src/lib/models.ts](mdc:src/lib/models.ts) 中注册：
```typescript
export interface AIModel {
  id: string;
  name: string;
  provider: string;
  endpoint?: string;
  maxTokens?: number;
  temperature?: number;
  // 其他模型特定配置
}
```

### 2. 服务接口统一标准
所有AI服务调用必须通过 [src/services/ai-service.ts](mdc:src/services/ai-service.ts)：
```typescript
interface AIServiceResponse {
  success: boolean;
  data?: any;
  error?: string;
  usage?: {
    inputTokens: number;
    outputTokens: number;
    totalTokens: number;
  };
}
```

### 3. 错误处理机制
- **网络错误**: 实现重试机制，最多3次重试
- **API限额**: 检测并处理API配额限制
- **服务降级**: 主服务不可用时切换到备用服务
- **用户反馈**: 向用户提供清晰的错误信息

## Prompt工程规范

### 1. Prompt模板化
- **系统提示**: 在模型配置中定义标准系统提示
- **用户提示**: 使用模板变量实现动态提示生成
- **上下文管理**: 合理控制上下文窗口大小
- **版本控制**: 在代码注释中记录Prompt版本

### 2. Prompt优化原则
- **明确性**: 提示指令必须清晰明确
- **一致性**: 相同类型任务使用相似的提示结构
- **可测试**: 提示效果必须可量化测试
- **文档化**: 重要提示必须有使用说明

### 3. 上下文窗口管理
- **信息压缩**: 超长上下文需要智能压缩
- **优先级排序**: 重要信息优先保留
- **增量更新**: 支持增量式上下文更新
- **内存管理**: 及时释放不需要的上下文

## 多模型支持规范

### 1. 模型抽象层
- **统一接口**: 所有模型通过相同接口调用
- **能力适配**: 根据模型能力选择合适的处理方式
- **参数映射**: 不同模型参数的标准化映射
- **响应格式**: 统一的响应数据格式

### 2. 模型选择策略
- **任务匹配**: 根据任务类型自动选择最适合的模型
- **性能考虑**: 考虑模型的响应速度和准确性
- **成本优化**: 在保证质量的前提下优化成本
- **用户偏好**: 允许用户手动选择偏好模型

### 3. 负载均衡和容错
- **请求分发**: 智能分发请求到不同模型实例
- **健康检查**: 定期检查模型服务的可用性
- **故障转移**: 自动切换到可用的模型服务
- **监控告警**: 实时监控模型服务状态

## 数据流和状态管理

### 1. 请求数据流
```
用户输入 → 数据验证 → 模型选择 → API调用 → 响应处理 → 状态更新 → UI渲染
```

### 2. 状态管理规范
- **请求状态**: loading, success, error状态管理
- **历史记录**: 保存用户的对话历史
- **缓存策略**: 合理缓存AI响应结果
- **持久化**: 重要数据的本地持久化

### 3. 异步处理标准
- **Promise链**: 使用async/await处理异步操作
- **错误传播**: 确保错误能正确向上传播
- **取消机制**: 支持长时间请求的取消操作
- **进度反馈**: 为长时间操作提供进度反馈

## 性能优化规范

### 1. 请求优化
- **批量处理**: 支持批量API请求
- **请求去重**: 避免重复的API调用
- **缓存机制**: 缓存常用的AI响应
- **预加载**: 预测性加载常用模型

### 2. 响应优化
- **流式输出**: 支持AI响应的实时流式输出
- **分片处理**: 大响应数据的分片处理
- **压缩传输**: 使用适当的数据压缩
- **懒加载**: 按需加载AI生成的内容

### 3. 内存管理
- **对象池**: 复用AI请求对象
- **垃圾回收**: 及时清理不用的AI响应数据
- **内存监控**: 监控AI服务的内存使用
- **泄漏检测**: 检测和修复内存泄漏

## 安全和隐私规范

### 1. 数据安全
- **输入过滤**: 过滤用户输入的敏感信息
- **输出检查**: 检查AI输出的安全性
- **传输加密**: 确保数据传输的安全性
- **存储加密**: 敏感数据的加密存储

### 2. 隐私保护
- **数据最小化**: 只收集必要的用户数据
- **匿名化**: 对用户数据进行适当匿名化
- **访问控制**: 严格控制AI数据的访问权限
- **数据清理**: 定期清理过期的AI交互数据

### 3. 合规性要求
- **使用协议**: 遵守AI服务提供商的使用协议
- **数据保护**: 符合相关的数据保护法规
- **内容审核**: 实施适当的内容审核机制
- **使用记录**: 记录AI服务的使用情况

## 测试和监控规范

### 1. 测试策略
- **单元测试**: 测试AI服务的核心功能
- **集成测试**: 测试AI服务与其他模块的集成
- **性能测试**: 测试AI服务的性能表现
- **压力测试**: 测试高并发情况下的服务稳定性

### 2. 质量监控
- **响应时间**: 监控AI API的响应时间
- **成功率**: 监控API调用的成功率
- **错误率**: 统计和分析错误类型
- **用户满意度**: 收集用户对AI服务的反馈

### 3. 日志和调试
- **请求日志**: 记录重要的AI请求信息
- **错误日志**: 详细记录错误信息和堆栈跟踪
- **性能日志**: 记录性能相关的指标
- **调试工具**: 提供AI服务的调试工具

## 开发最佳实践

### 1. 代码组织
- **模块化**: 将AI服务功能模块化
- **可测试**: 代码设计要便于单元测试
- **可扩展**: 易于添加新的AI模型和功能
- **可维护**: 保持代码的清晰和可读性

### 2. 配置管理
- **环境分离**: 不同环境使用不同的AI配置
- **敏感信息**: API密钥等敏感信息使用环境变量
- **版本管理**: 对AI模型版本进行管理
- **动态配置**: 支持运行时配置修改

### 3. 文档要求
- **API文档**: 详细的AI服务API文档
- **使用示例**: 提供清晰的使用示例
- **故障排除**: 常见问题的解决方案
- **更新日志**: 记录AI服务的更新历史

